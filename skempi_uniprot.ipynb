{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)\n",
    "import csv\n",
    "import numpy as np\n",
    "from Bio.PDB.Polypeptide import three_to_one, one_to_three                           \n",
    "import math\n",
    "import requests as r\n",
    "from Bio import SeqIO\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(fName):\n",
    "    df = pd.read_csv(fName)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data: (6794, 29)\n"
     ]
    }
   ],
   "source": [
    "def load_pd(fName):\n",
    "    df = pd.read_csv(fName)\n",
    "    df = df.dropna(subset = ['Affinity_mut_parsed', 'Affinity_wt_parsed', 'Temperature'])\n",
    "    return df\n",
    "\n",
    "skepiIn = \"C:/Users/amber/Study_Documents/intern/inno/ppi with binding affinity/skempi/skempi_v2.csv\"\n",
    "ppi = load_pd(skepiIn)\n",
    "print(\"Size of the data:\", ppi.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wild-type library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get dG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dg(ent_name, chain_ID0, chain_ID1, kd, dg_info):\n",
    "    \n",
    "    w_name0 = ent_name +'_'+chain_ID0\n",
    "    w_name1 =  ent_name +'_'+chain_ID1\n",
    "    #print(ent_name)\n",
    "    # transfer kd unit to M\n",
    "    \n",
    "    dg = (8.314/4184)*(float(298)) * math.log(float(kd))\n",
    "   \n",
    "    info = w_name0 + \" \" +  w_name1 + \" \" + str(dg)\n",
    "    dg_info.append(info)\n",
    "    return dg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "dg_info = []\n",
    "wild_list = []\n",
    "\n",
    "cnt_single_chain = cnt_both_chain = 0\n",
    "\n",
    "f1 = open(\"./skempi/wild.seq.txt\", \"w\")\n",
    "f2 = open(\"./skempi/wild.dg.txt\", \"w\")\n",
    "#print(ppi.shape)\n",
    "\n",
    "for i in range(6794):\n",
    "    data = ppi.iloc[i]\n",
    "    complex_id = data[0]\n",
    "    if complex_id not in wild_list:\n",
    "        ent_name = data[0][:4]\n",
    "    #     .lower()\n",
    "        #print(ent_name)\n",
    "        chains = data[0].split('_')[1:]\n",
    "        #print(chains)\n",
    "        assert(len(chains) == 2)\n",
    "    #     print(i, len(ppi))\n",
    "        chain_ID0 = chains[0]\n",
    "        chain_ID1 = chains[1]\n",
    "\n",
    "        # there also exists cases the two chains in one side\n",
    "        if len(chain_ID0) == 1 and len(chain_ID1) == 1:\n",
    "            kd = data['Affinity_wt_parsed']\n",
    "            #print(kd)\n",
    "            temp = data['Temperature'].strip()[:3]\n",
    "            #print(temp)\n",
    "            \n",
    "            get_dg(ent_name, chain_ID0, chain_ID1, kd, dg_info)\n",
    "            wild_list.append(complex_id)\n",
    "\n",
    "print(len(wild_list))\n",
    "\n",
    "for elem in dg_info:\n",
    "    print(elem, file=open(\"./skempi/wild.dg.txt\", \"a\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 225 unique wild-type protein complex with two chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get sequencing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get uniprot id for complex in wild_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the corresponding file, connects PDB code with uniprot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          PDB CHAIN SP_PRIMARY  RES_BEG  RES_END PDB_BEG PDB_END  SP_BEG  \\\n",
       "0       101m     A     P02185        1      154       0     153       1   \n",
       "1       102l     A     P00720        1       40       1      40       1   \n",
       "2       102l     A     P00720       42      165      41    None      41   \n",
       "3       102m     A     P02185        1      154       0     153       1   \n",
       "4       103l     A     P00720        1       40       1    None       1   \n",
       "...      ...   ...        ...      ...      ...     ...     ...     ...   \n",
       "616805  9xia     A     P24300        1      388       1    None       1   \n",
       "616806  9xim     A     P12851        1      393    None     394       2   \n",
       "616807  9xim     B     P12851        1      393    None     394       2   \n",
       "616808  9xim     C     P12851        1      393    None     394       2   \n",
       "616809  9xim     D     P12851        1      393    None     394       2   \n",
       "\n",
       "        SP_END  \n",
       "0          154  \n",
       "1           40  \n",
       "2          164  \n",
       "3          154  \n",
       "4           40  \n",
       "...        ...  \n",
       "616805     388  \n",
       "616806     394  \n",
       "616807     394  \n",
       "616808     394  \n",
       "616809     394  \n",
       "\n",
       "[616810 rows x 9 columns]>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filein = \"C:/Users/amber/Study_Documents/intern/inno/ppi with binding affinity/pdb_chain_uniprot.tsv\"\n",
    "pdb_uniprot = pd.read_csv(filein, sep='\\t')\n",
    "pdb_uniprot.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PDB',\n",
       " 'CHAIN',\n",
       " 'SP_PRIMARY',\n",
       " 'RES_BEG',\n",
       " 'RES_END',\n",
       " 'PDB_BEG',\n",
       " 'PDB_END',\n",
       " 'SP_BEG',\n",
       " 'SP_END']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pdb_uniprot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_pdb (ent_name, chain_id, uniprot_dic, unstored_complex):\n",
    "    \n",
    "    data = pdb_uniprot.loc[(pdb_uniprot['PDB'] == ent_name.lower()) & (pdb_uniprot['CHAIN'] == chain_id), 'SP_PRIMARY']\n",
    "    if data.empty:\n",
    "        pdb_id = ent_name + \"_\" + chain_id\n",
    "        unstored_complex.append(pdb_id)\n",
    "    else:\n",
    "        uniprot_id = data.values\n",
    "        pdb_id = ent_name + \"_\" + chain_id\n",
    "        #print(uniprot_id)\n",
    "        #print(pdb_id)\n",
    "        uniprot_dic[pdb_id] = uniprot_id[0]\n",
    "\n",
    "unstored_complex = []\n",
    "uniprot_dic = {}\n",
    "for item in wild_list:\n",
    "    #print(item)\n",
    "    ent_name = item[:4]\n",
    "    #     .lower()\n",
    "    #print(ent_name)\n",
    "    chains = item.split('_')[1:]\n",
    "    #print(chains)\n",
    "    assert(len(chains) == 2)\n",
    "#     print(i, len(ppi))\n",
    "    chain_ID0 = chains[0]\n",
    "    chain_ID1 = chains[1]\n",
    "    get_seq_pdb(ent_name, chain_ID0, uniprot_dic, unstored_complex)\n",
    "    get_seq_pdb(ent_name, chain_ID1, uniprot_dic, unstored_complex)\n",
    "\n",
    "#print(uniprot_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(uniprot_dic))\n",
    "print(len(unstored_complex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1JCK_A',\n",
       " '2NOJ_B',\n",
       " '4HRN_A',\n",
       " '4KRL_B',\n",
       " '4KRO_B',\n",
       " '4KRP_B',\n",
       " '3EQS_B',\n",
       " '3LNZ_B',\n",
       " '3EQY_C',\n",
       " '5M2O_B',\n",
       " '5XCO_B',\n",
       " '5UFE_B',\n",
       " '5UFQ_C']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstored_complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 chains without uniprot code. Obtain this sequencing data from PDB lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B0FXJ2']\n",
      "['B0FXJ2']\n"
     ]
    }
   ],
   "source": [
    "# def get_seq_pdb (ent_name, chain_id, uniprot_list):\n",
    "    \n",
    "#     data = pdb_uniprot.loc[(pdb_uniprot['PDB'] == ent_name.lower()) & (pdb_uniprot['CHAIN'] == chain_id), 'SP_PRIMARY']\n",
    "#     #print(data)\n",
    "#     uniprot_id = data.values\n",
    "#     print(uniprot_id)\n",
    "#     uniprot_list += list(uniprot_id)\n",
    "    \n",
    "# uniprot_list=[]\n",
    "# get_seq_pdb('1CSE','E',uniprot_list)\n",
    "# print(uniprot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get sequencing from uniprot id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566996, 2)\n"
     ]
    }
   ],
   "source": [
    "uniprot_in = \"C:/Users/amber/Study_Documents/intern/inno/ppi with binding affinity/uniprot.csv\"\n",
    "uniprot_seq = load_file(uniprot_in)\n",
    "print(uniprot_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_uniprot_lib (label):\n",
    "    cID=label\n",
    "\n",
    "    baseUrl=\"http://www.uniprot.org/uniprot/\"\n",
    "    currentUrl=baseUrl+cID+\".fasta\"\n",
    "    response = r.post(currentUrl)\n",
    "    cData=''.join(response.text)\n",
    "\n",
    "    Seq=StringIO(cData)\n",
    "    pSeq=list(SeqIO.parse(Seq,'fasta'))\n",
    "    result =str(pSeq[0].seq)\n",
    "    return result\n",
    "\n",
    "#seq_uniprot_lib('Q07011')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_uniprot (uniprot_id, pdb_id, seq_uniprot):\n",
    "    \n",
    "    data = uniprot_seq.loc[uniprot_seq['uniprot_id'] == uniprot_id,'pro_seq']\n",
    "    if data.empty:\n",
    "        seq_from_lib = seq_uniprot_lib(uniprot_id)\n",
    "        seq_data = pdb_id + ' ' + seq_from_lib\n",
    "        seq_uniprot.append(seq_data)\n",
    "    else:\n",
    "        seq = data.values[0]\n",
    "        #print(seq)\n",
    "        seq_data = pdb_id + ' ' + seq\n",
    "        seq_uniprot.append(seq_data)\n",
    "        #print(seq_uniprot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_uniprot = []\n",
    "for item in uniprot_dic:\n",
    "    pdb_id = item\n",
    "    #print(uniprot_id)\n",
    "    uniprot_id = uniprot_dic[pdb_id]\n",
    "    #print(pdb_id)\n",
    "    get_seq_uniprot(uniprot_id, pdb_id, seq_uniprot)  \n",
    "\n",
    "for elem in seq_uniprot:\n",
    "    print(elem, file=open(\"./skempi/wild.seq.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get seq from PDB bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the pdb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JCK\n",
      "Downloading PDB structure '1JCK'...\n",
      "2NOJ\n",
      "Downloading PDB structure '2NOJ'...\n",
      "4HRN\n",
      "Downloading PDB structure '4HRN'...\n",
      "4KRL\n",
      "Downloading PDB structure '4KRL'...\n",
      "4KRO\n",
      "Downloading PDB structure '4KRO'...\n",
      "4KRP\n",
      "Downloading PDB structure '4KRP'...\n",
      "3EQS\n",
      "Downloading PDB structure '3EQS'...\n",
      "3LNZ\n",
      "Downloading PDB structure '3LNZ'...\n",
      "3EQY\n",
      "Downloading PDB structure '3EQY'...\n",
      "5M2O\n",
      "Downloading PDB structure '5M2O'...\n",
      "5XCO\n",
      "Downloading PDB structure '5XCO'...\n",
      "5UFE\n",
      "Downloading PDB structure '5UFE'...\n",
      "5UFQ\n",
      "Downloading PDB structure '5UFQ'...\n"
     ]
    }
   ],
   "source": [
    "for item in unstored_complex:\n",
    "    ent_name = item[:4]\n",
    "    print(ent_name)\n",
    "    pdbl = PDBList()\n",
    "    assert(len(ent_name) ==4)\n",
    "    pdbl.retrieve_pdb_file(ent_name, pdir = './skempi/PDBs/', file_format='pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(ent_name, chain, seqinfo):\n",
    "#     print(ent_names, chain_ID0, chain_ID1)\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure(ent_name, './skempi/PDBs/pdb'+ ent_name.lower() + '.ent')\n",
    "    #     assert(len(structure) == 1)\n",
    "    model = structure[0]\n",
    "\n",
    "    w_name = ent_name+'_'+ chain\n",
    "    if w_name not in seqinfo:\n",
    "        w_seq = ''\n",
    "\n",
    "        chain = model[chain]\n",
    "        ppb = PPBuilder()\n",
    "        for pp in ppb.build_peptides(chain):\n",
    "            w_seq += pp.get_sequence()\n",
    "        #print(type(w_seq))\n",
    "        sequence = w_name + \" \" + str(w_seq)\n",
    "        seqinfo.append(sequence)\n",
    "        \n",
    "    return seqinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqinfo = []\n",
    "\n",
    "for item in unstored_complex:\n",
    "    ent_name = item[:4]\n",
    "    chain = item[-1]\n",
    "    get_seq(ent_name, chain, seqinfo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1JCK_A AVTQSPRNKVAVTGGKVTLSCQQTNNHNNMYWYRQDTGHGLRLIHYSYGAGSTEKGDIPDGYKASRPSQEQFSLILELATPSQTSVYFCASGGGRGSYAEQFFGPGTRLTVLEDLRQVTPPKVSLFEPSKAEIANKQKATLVCLARGFFPDHVELSWWVNGKEVHSGVSTDPQAYKESNYSYCLSSRLRVSATFWHNPRNHFRCQVQFHGLSEEDKWPEGSPKPVTQNISAEAWGRAD',\n",
       " '2NOJ_B NKKVVDAQKAVELFKRTRTVATHRKAQRAVNLIHFQHSYEKKKLQRQIDLVLKYNTLK',\n",
       " '4HRN_A DLGKKLLEAARAGQDDEVRILMANGADVNAKDEYGLTPLYLATAHGHLEIVEVLLKNGADVNAVDAIGFTPLHLAAFIGHLEIAEVLLKHGADVNAQDKFGKTAFDISIGNGNEDLAEILQ',\n",
       " '4KRL_B QVKLEESGGGSVQTGGSLRLTCAASGRTSRSYGMGWFRQAPGKEREFVSGISWRGDSTGYADSVKGRFTISRDNAKNTVDLQMNSLKPEDTAIYYCAAAAGSAWYGTLYEYDYWGQGTQVTV',\n",
       " '4KRO_B QVQLQESLSCAASGRTFSSYAMGWFRQAPGKQREFVAAIRWSGGYTYYTDSVKGRFTISRDNAKTTVYLQMNSLKPEDTAVYYCAATYLSSDYSRYALPQRPLDYDYWGQGTQVTV',\n",
       " '4KRP_B EVQLVESGGGLLSCAASGRTFSSYAMGWFRQAPGKEREFVVAINWSSGSTYYADSVKGRFTISRDNAKNTMYLQMNSLKPEDTAVYYCAAGYQINSGNYNFKDYEYDYWGQGTQVT',\n",
       " '3EQS_B TSFAEYWNLLS',\n",
       " '3LNZ_B TSFAEYWALLS',\n",
       " '3EQY_C TSFAEYWNLLSP',\n",
       " '5M2O_B SVQKFPGDANCDGIVDISDAVLIMQTMANPSKYQMTDKGRINADVTGNSDGVTVLDAQFIQSYCLGLVELPPVE',\n",
       " '5XCO_B RRRRCPLYISYDPVCRRRR',\n",
       " '5UFE_B ATVKFTGEEKQVDISKIKWVIRWGQYIWFKYDEDAKGWGYVSEKDAPKELLQML',\n",
       " '5UFQ_C ATVKFTGEEKQVDISKIKWVIRWGQYIWFKYDEGGKGWGYVSEKDAPKELLQMLKK']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in seqinfo:\n",
    "    print(elem, file=open(\"./skempi/wild.seq.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mutation sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_dg_info= []\n",
    "mutated_seq_list= []\n",
    "\n",
    "f3 = open(\"./skempi/mut.seq.txt\", \"w\")\n",
    "f4 = open(\"./skempi/mut.dg.txt\", \"w\")\n",
    "#print(ppi.shape)\n",
    "\n",
    "for i in range(6794):\n",
    "    data = ppi.iloc[i]\n",
    "    complex_id = data[0]\n",
    "    ent_name = data[0][:4]\n",
    "    chains = data[0].split('_')[1:]\n",
    "    #print(chains)\n",
    "    assert(len(chains) == 2)\n",
    "    #     print(i, len(ppi))\n",
    "    chain_ID0 = chains[0]\n",
    "    chain_ID1 = chains[1]\n",
    "\n",
    "    # there also exists cases the two chains in one side\n",
    "    if len(chain_ID0) == 1 and len(chain_ID1) == 1:\n",
    "        kd = data['Affinity_mut_parsed']\n",
    "        #print(kd)\n",
    "        temp = data['Temperature'].strip()[:3]\n",
    "        #print(temp)\n",
    "        mutation_site = data['Mutation(s)_cleaned']\n",
    "        mutated_chain_ID0 = chain_ID0 + \"_\" + mutation_site\n",
    "        mutated_chain_ID1 = chain_ID1 + \"_\" + mutation_site\n",
    "        get_dg(ent_name, mutated_chain_ID0, mutated_chain_ID1, kd, mutated_dg_info)\n",
    "        mutated_seq_list.append(ent_name + \"_\" + mutated_chain_ID0)\n",
    "        mutated_seq_list.append(ent_name + \"_\" + mutated_chain_ID1)\n",
    "\n",
    "for elem in mutated_dg_info:\n",
    "    print(elem, file=open(\"./skempi/mut.dg.txt\", \"a\"))\n",
    "\n",
    "f3.close()\n",
    "f4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 4165 mutated complex pair with two chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1TM1_E_TI39D',\n",
       " '1TM1_I_TI39D',\n",
       " '1TM1_E_TI39A',\n",
       " '1TM1_I_TI39A',\n",
       " '1TM1_E_EI41A',\n",
       " '1TM1_I_EI41A',\n",
       " '1TM1_E_TI39A,EI41A',\n",
       " '1TM1_I_TI39A,EI41A',\n",
       " '1TM1_E_TI39D,EI41A',\n",
       " '1TM1_I_TI39D,EI41A']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mutated_seq_list)\n",
    "mutated_seq_list[40:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequencing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read wild-type txt into dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_wild = {}\n",
    "with open(\"./skempi/wild.seq.txt\") as f:\n",
    "    for line in f:\n",
    "       (name, sequence) = line.split()\n",
    "       seq_wild[name] = sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "T\n",
      "V\n",
      "error in 1TM1_I_TI39D,EI41A\n",
      "41\n",
      "E\n",
      "L\n",
      "error in 1TM1_I_TI39D,EI41A\n"
     ]
    }
   ],
   "source": [
    "def mutation_on_seq(los):\n",
    "    info = los.split(\"_\")\n",
    "    ent_name = info[0]\n",
    "    chain_id = info[1]\n",
    "    ent_id = \"_\".join(info[:2])\n",
    "    #print(ent_id)\n",
    "    lo_mutation = info[2].split(\",\")\n",
    "    #print(lo_mutation)\n",
    "\n",
    "    for item in lo_mutation:\n",
    "        mutation_chain = item[1]\n",
    "        mutation_pos = int(item[2:-1])\n",
    "        print(mutation_pos)\n",
    "        r_w = item[0]\n",
    "        print(r_w)\n",
    "        r_m = item[-1]\n",
    "        \n",
    "        if chain_id == mutation_chain:\n",
    "            seq_w = seq_wild[ent_id]\n",
    "            seq = list(seq_w)\n",
    "            print(seq[mutation_pos - 1])\n",
    "            if seq[mutation_pos -1] == r_w:\n",
    "                seq[mutation_pos - 1] = r_m\n",
    "                seq_m = \"\".join(seq)\n",
    "                seq_mutated[los] = seq_m\n",
    "            else:\n",
    "                errormeg = \"error in \" + los\n",
    "                print(errormeg)\n",
    "\n",
    "\n",
    "mutation_on_seq('1TM1_I_TI39D,EI41A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AKKVILQDKPAAQIIVLPVGTIVTMEYRIDRVRLFVDRLDNIAQVPRVG'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_wild['1TM1_I'][35:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then find the uniprot sequencing is not always corresponding to pdb sequencing**\n",
    "\n",
    "have to use pdb file to extract sequencing data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a542ca580817fc4dd55327026e074e2fa0cd470fc5dee9350c2d8b13822db8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
